{"question_answering": "question_answering is a function that uses a pre-trained language model to answer questions based on a given context.\n        You can choose one model from: 'distilbert-base-uncased-distilled-squad', 'deepset/minilm-uncased-squad2', 'etalab-ia/camembert-base-squadFR-fquad-piaf'.\n\n        Action Input: {\"model_id\" : \"distilbert-base-uncased-distilled-squad\", \"question\" : \"When did the first moon landing occur?\", \"context\" : \"The first manned moon landing was achieved by the United States on July 20, 1969, in the Apollo 11 mission.\"}\n        ", "sentence_similarity": "sentence_similarity is a function that uses a pre-trained language model to calculate the similarity between two sentences.\n        You can choose one model from: 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'sentence-transformers/paraphrase-MiniLM-L6-v2'.\n\n        Action Input: {\"model_id\" : \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \"text\" : \"The cat is sitting on the mat.\", \"context\" : \"The dog is sleeping on the couch.\"}\n        ", "text_classification": "text_classification is a function that uses a pre-trained language model to classify text into pre-defined categories.\n        You can choose one model from: 'roberta-base-openai-detector', 'cardiffnlp/twitter-xlm-roberta-base-sentiment', 'nlptown/bert-base-multilingual-uncased-sentiment'.\n\n        Action Input: {\"model_id\" : \"roberta-base-openai-detector\", \"text\" : \"This movie was amazing. The acting was great and the plot was interesting.\"}\n        ", "token_classification": "token_classification is a function that uses a pre-trained language model to classify tokens in a text into pre-defined categories such as named entities, part-of-speech, or punctuation marks.\n        You can choose one model from: 'StanfordAIMI/stanford-deidentifier-base', 'Jean-Baptiste/camembert-ner-with-dates', 'yanekyuk/bert-uncased-keyword-extractor'.\n\n        Action Input: {\"model_id\" : \"StanfordAIMI/stanford-deidentifier-base\", \"text\" : \"Steve Jobs was the CEO of Apple Inc.\"}\n        ", "text2text_generation": "text2text_generation is a function that uses a pre-trained language model to generate text based on a given prompt or input text.\n        You can choose one model from: 'tuner007/pegasus_paraphrase', 'Salesforce/codet5-base', 'Babelscape/rebel-large'.\n\n        Action Input: {\"model_id\" : \"tuner007/pegasus_paraphrase\", \"text\" : \"In recent years, there has been a growing concern over the impact of technology on society. Some argue that technology has made our lives better, while others believe that it has caused more harm than good.\"}\n        ", "summarization": "summarization is a function that uses a pre-trained language model to summarize a long piece of text into a shorter version.\n        You can choose one model from: 'sshleifer/distilbart-cnn-6-6', 'sshleifer/distilbart-cnn-12-6', 'google/pegasus-cnn_dailymail'.\n\n        Action Input: {\"model_id\" : \"sshleifer/distilbart-cnn-6-6\", \"text\" : \"In a press conference held today, the government announced a new policy to reduce carbon emissions by 50% over the next decade. The policy includes a range of measures such as investing in renewable energy, incentivizing businesses to reduce their carbon footprint, and introducing a carbon tax.\"}\n        ", "translation": "translation is a function that uses a pre-trained language model to translate text from one language to another.\n        You can choose one model from: 'Helsinki-NLP/opus-mt-mul-en', 'Helsinki-NLP/opus-mt-zh-en', 'Helsinki-NLP/opus-mt-en-zh', 'Helsinki-NLP/opus-mt-fr-en'.\n\n        Action Input: {\"model_id\" : \"Helsinki-NLP/opus-mt-mul-en\", \"text\" : \"El clima est\u00e1 agradable hoy.\"}\n        ", "conversational": "conversational is a function that uses a pre-trained language model to generate responses to a given input text in a conversational manner, while also taking into account past user inputs and generated responses.\n        You can choose one model from: 'facebook/blenderbot-400M-distill ', 'microsoft/DialoGPT-large', 'deepparag/Aeona'.\n\n        Action Input: {\"model_id\" : \"microsoft/DialoGPT-large\", \"text\" : \"What did you think of the movie?\", \"past_user_inputs\": \"I really enjoyed the movie. It had a great plot and interesting characters.\", \"generated_responses\": \"I'm glad you liked it. I thought the acting was really good.\"}\n        ", "text_generation": "text_generation is a function that uses a pre-trained language model to generate text based on a given prompt or input text.\n        You can choose one model from: 'bigscience/bloomz', \"bigscience/bloom-560m\", \"EleutherAI/gpt-neox-20b\".\n\n        Action Input: {\"model_id\" : \"bigscience/bloomz\", \"text\" : \"Artificial intelligence is\"}\n        ", "visual_question_answering": "visual_question_answering is a function that uses a pre-trained visual question answering model to answer a question based on a given image and text.\n\n        - dandelin/vilt-b32-finetuned-vqa\n        - azwierzc/vilt-b32-finetuned-vqa-pl\n        - Bingsu/temp_vilt_vqa\n        - tufa15nik/vilt-finetuned-vqasi\n\n        Action Input: {\"model_id\" : \"dandelin/vilt-b32-finetuned-vqa\", \"image_file_name\" : \"sample_image.jpg\", \"text\" : \"What is the color of the car?\"}\n        ", "document_question_answering": "document_question_answering is a function that uses a pre-trained document question answering model to answer a question based on a given document image and text.\n\n        - impira/layoutlm-document-qa\n        - tiennvcs/layoutlmv2-base-uncased-finetuned-infovqa\n        - pardeepSF/layoutlm-vqa\n\n        Action Input: {\"model_id\" : \"tiennvcs/layoutlmv2-base-uncased-finetuned-docvqa\", \"image\" : \"document_image.jpg\", \"text\" : \"What is the date of the invoice?\"}\n        ", "image_to_image": "image_to_image is a function that uses a pre-trained image-to-image translation model to transform an input image into an output image.\n\n        - lambdalabs/sd-image-variations-diffusers\n\n        Action Input: {\"model_id\" : \"lambdalabs/sd-image-variations-diffusers\", \"image\" : \"input_image.jpg\"}\n        ", "text_to_image": "text_to_image is a function that uses a pre-trained text-to-image generation model to generate an image based on a given text description.\n\n        - prompthero/openjourney-v4\n        - hakurei/waifu-diffusion\n        - gsdf/Counterfeit-V2.0\n\n        Action Input: {\"model_id\" : \"andite/pastel-mix\", \"text\" : \"A beautiful sunset over the ocean with palm trees in the foreground.\"}\n        ", "image_segmentation": "image_segmentation is a function that uses a pre-trained image segmentation model to segment an input image into different objects or regions.\n\n        - nvidia/segformer-b5-finetuned-ade-640-640\n        - nvidia/segformer-b1-finetuned-cityscapes-1024-1024\n        - facebook/detr-resnet-50-panoptic\n\n        Action Input: {\"model_id\" : \"nvidia/segformer-b5-finetuned-ade-640-640\", \"image\" : \"input_image.jpg\"}\n        ", "object_detection": "object_detection is a function that uses a pre-trained object detection model to detect objects in an input image.\n\n        - facebook/detr-resnet-50\n        - hustvl/yolos-tiny\n\n        Action Input: {\"model_id\" : \"facebook/detr-resnet-50\", \"image\" : \"input_image.jpg\"}\n        ", "image_classification": "image_classification is a function that uses a pre-trained image classification model to classify an input image into different categories.\n\n        - google/vit-base-patch16-224\n        - facebook/deit-base-distilled-patch16-224\n        - microsoft/dit-base-finetuned-rvlcdip\n\n        Action Input: {\"model_id\" : \"google/vit-base-patch16-224\", \"image\" : \"input_image.jpg\"}\n        ", "image_to_text": "image_to_text is a function that uses a pre-trained OCR (Optical Character Recognition) model to recognize text in an input image.\n\n        - nlpconnect/vit-gpt2-image-captioning\n        - ydshieh/vit-gpt2-coco-en\n        - microsoft/trocr-small-handwritten\n\n        Action Input: {\"model_id\" : \"microsoft/trocr-base-printed\", \"image\" : \"input_image.jpg\"}\n        ", "text_to_speech": "text_to_speech is a function that uses a pre-trained text-to-speech model to convert a given input text into a corresponding speech signal.\n\n        - speechbrain/tts-tacotron2-ljspeech\n        - facebook/fastspeech2-en-ljspeech\n        - espnet/kan-bayashi_ljspeech_joint_finetune_conformer_fastspeech2_hifigan\n\n        Action Input: {\"model_id\" : \"facebook/fastspeech2-en-ljspeech\", \"text\" : \"Hello, how are you?\"}\n        ", "automatic_speech_recognition": "automatic_speech_recognition is a function that uses a pre-trained automatic speech recognition model to transcribe a given audio file into text.\n\n        - openai/whisper-large-v2\n        - openai/whisper-base\n        - jonatasgrosman/wav2vec2-large-xlsr-53-english\n        - openai/whisper-medium\n\n        Action Input: {\"model_id\" : \"facebook/wav2vec2-base-960h\", \"audio_file_name\" : \"sample_audio.flac\"}\n        ", "audio_to_audio": "audio_to_audio is a function that uses a pre-trained audio-to-audio model to enhance or separate a given audio file into one or more audio files.\n\n        NOTE: you can check the result by using automatic-speech-recognition models.\n\n        - JorisCos/DCCRNet_Libri1Mix_enhsingle_16k\n        - speechbrain/sepformer-wham\n        - facebook/xm_transformer_unity_hk-en\n        - facebook/xm_transformer_sm_all-en\n\n        Action Input: {\"model_id\" : \"speechbrain/sepformer-wham\", \"audio_file_name\" : \"mixed_audio.flac\"}\n        ", "audio_classification": "audio_classification is a function that uses a pre-trained audio classification model to classify a given audio file into one or more categories.\n\n        - ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\n        - anton-l/wav2vec2-base-ft-keyword-spotting\n\n        Action Input: {\"model_id\" : \"anton-l/wav2vec2-base-ft-keyword-spotting\", \"audio\" : \"sample_audio.flac\"}\n        "}